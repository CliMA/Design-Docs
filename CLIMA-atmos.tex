
\documentclass[12pt]{article}

%\usepackage[pdf]{pstricks}
%\usepackage[on]{auto-pst-pdf}

\topmargin 0in
\oddsidemargin 0.25in
\evensidemargin 0.25in
\textwidth 6.0in
\textheight 9.0in

\include{FXG_Macros}

\begin{document}
%\frontmatter
\title{ \textcolor{red}{Software Design Document for the Climate Machine Atmospheric Models} }
\author{ }
%\author{Francis X. Giraldo \\
%Department of Applied Mathematics \\
%Naval Postgraduate School \\
%Monterey, CA 93943-5216}

\maketitle
\tableofcontents
%\listoffigures
%\listoftables
%\listofalgorithms

%\mainmatter

%\part{Introduction}

%Background and Motivation

\section{Introduction}
\label{sec:introduction}

This document highlights the design specifications for the Machine Learning Atmospheric Model (MLAM). MLAM is a suite of non-hydrostatic atmospheric models required by the Climate Machine  project (\textbf{FXG:Need a new name for the components: e.g., Clima-atmos or CLIMAa?}).  The two non-hydrostatic atmospheric models described are 
\begin{enumerate}
\item a Large-Eddy Simulation (LES) model and 
\item a global model.
\end{enumerate}
This document outlines the details of these two models in terms of 
\begin{enumerate}
\item governing equations  used for both models
\item numerical discretization methods
\item programming language and continuous integration approach.
\end{enumerate}

% !TEX root = main.tex

\section{Governing Equations}
\label{sec:governing_equations}

The governing equations of motion for the nonhydrostatic atmospheric models are

\begin{subequations}
\label{eq:governing_equations}
\begin{equation}
\diff{\rho}{t} + \divergence \vc{U} = 0
\label{eq:governing_equations/mass}
\end{equation}
\begin{equation}
\diff{\vc{U}}{t} + \divergence \left( \frac{ \vc{U} \otimes \vc{U} }{\rho} + P \vc{I}_3 \right) = \divergence \left( \mu \grad \vc{U} \right) - f \vc{r} \times \vc{U} - \rho g \vc{r}
\label{eq:governing_equations/momentum}
\end{equation}
\begin{equation}
\diff{\Theta}{t} + \divergence \left( \frac{ \Theta  \vc{U} }{\rho} \right)  = \divergence \left( \mu \grad \vc{\Theta} \right)
\label{eq:governing_equations/theta}
\end{equation}
\end{subequations}
where $\vc{U}=\rho \vc{u}$, $\vc{u}=\left(u,v,w\right)\transpose$, and $\Theta=\rho \theta$. In addition, in Eq.\eqref{eq:governing_equations/momentum} $\vc{I}_3$ is the rank-3 identity matrix, and the pressure is defined as follows:
\[
P=P_A \left(  \frac{R \Theta }{P_A}  \right)^{\gamma}
\]
where $R$ is the gas constant, $P_A$ is the atmospheric pressure, $\gamma=\frac{c_p}{c_v}$, $f$ is the Coriolis function, $\vc{r}$ is the radial vector, and $g$ is the gravitational constant.

In Eqs.\ \eqref{eq:governing_equations/momentum} and \eqref{eq:governing_equations/theta} the term $\mu$ represents the viscosity coefficient  computed as follows: for the LES model, it is computed from the specific turbulence closure used (e.g., Lilly-Smagorinsky or another less dissipative model) and for the global model it is computed as the minimum artificial viscosity required to avoid Gibbs phenomena.

Eqs.\ \eqref{eq:governing_equations} are written in Cartesian coordinates and are equally applicable to both the LES model as well as the global model.  The difference between the LES and global models is how the buoyancy term (last term on right-hand-side of Eq.\  \eqref{eq:governing_equations/momentum}) is defined.  For this reason, we define the buoyancy term with respect to the radial component which is $\vc{r}=(0,0,1)$ in the LES model and $\vc{r}=\frac{(x,y,z)}{|| \vc{x} ||}$ on the sphere, where $(x,y,z)$ are the coordinates of each point on the globe.

% !TEX root = main.tex

\section{Numerical Methods}
\label{sec:numerical_methods}

In order to describe the numerical methods used to solve the governing equations numerically, let us write the equations in the following compact form

\[
\diff{\vc{q}}{t} = S(\vc{q})
\]
where $\vc{q}$
\[
\vc{q}=\left( \begin{array}{c}
\rho \\
\vc{U} \\
\Theta
\end{array}
\right)
\]
 is the solution vector, 
 and 
 \[
 S(\vc{q}) = - \nabla \cdot \vc{F} - \mathcal{S}(\vc{q})
 \]
 is the right-hand-side containing the spatial operators where 
 \[
 \vc{F}=\left( \begin{array}{c}
 \vc{U} \\
 \frac{\vc{U} \otimes \vc{U}}{\rho} + P \vc{I}_3 - \left( \mu \grad \vc{U} \right) \\
\frac{\Theta \vc{U}}{\rho} - \left( \mu \grad \Theta \right)
\end{array}
\right)
 \]
 is the flux tensor and
 \[
 \mathcal{S}(\vc{q})=\left( \begin{array}{c}
 0 \\
 f \vc{r} \times \vc{U} + \rho g \vc{r} \\
0 
\end{array}
\right)
 \]
contains the source terms. 

\subsection{Spatial Discretization Methods}
For the spatial discretization methods, we propose to use variants of the discontinuous Galerkin (dG) method with a tensor-product bases (see, e.g., \cite{giraldo:2008a, abdi:2016}. That is, we propose to use hexahedral (cube) elements in three dimensions.  The nodal tensor-product dG methods are extremely accurate and efficient.  For example, using a basis comprised of $N$th degree Lagrange polynomials results in approximately an accuracy of $\order(\Delta x^{N+1})$. Furthermore, using inexact integration results in a per-element complexity of $\order(N^{d+1})$ for constructing derivatives, where $d$ denotes the dimension of the space. 

For the LES model, we will also consider fully three-dimensional dG methods. For the global model, it may be beneficial to consider a hybrid approach whereby the horizontal direction (along the spherical manifold) uses dG while a more standard method (open for discussion) may be used in the vertical.  Along certain directions, it may be advantageous to use uniform grid resolution in order to take advantage of larger time-steps (e.g., in using uniform grids for the global or LES model along the vertical direction would allow for some of the grid aspect ratio stiffness to be reduced).  \textbf{FXG: Need references}.

\subsection{Time-Discretization Methods}

In order to circumvent the time-step restriction due to the fast moving acoustic waves, we will rely on implicit-explicit (IMEX) methods . For the LES model, if the aspect ratio of the horizontal to vertical grid spacing is near unity, it will be beneficial to use fully 3D-IMEX methods.  For the global atmospheric model, we propose to use 1D-IMEX methods whereby the time-integrator is fully explicit in the horizontal direction (HE) and implicit in the vertical direction (so-called HEVI schemes).

We propose to use a general family of additive Runge-Kutta methods (ARK) methods for both the 1D and 3D IMEX approaches (see, e.g., \cite{giraldo:2013} for 1D and 3D-IMEX methods based on ARKs). Note that adding fully-implicit Runge-Kutta (IRK) methods to the 3D-IMEX approach is quite trivial so this can be included as an option. Fully-implicit methods have no time-step restriction with respect to stability.

To get a sense of how the ARK approach works, let us partition the right-hand-side function $S(\vc{q})$ into its linear $L(\vc{q})$ and nonlinear $N(\vc{q})$ parts where the stiffness due to grid spacing or acoustic waves are contained in $L(\vc{q})$.  This then allow us to write the semi-discrete form (in space) as follows
\[
\diff{\qvector}{t} = L(\qvector) + N(\qvector) 
\]
which can now be discretized in time.  First we compute the stage values
\[
\vc{Q}^{(i+1)}=\qvector^n + \Delta t \sum_{k=0}^{i} \left( a_k N(\vc{Q}^{(k)}) \right) + \Delta t \sum_{k=0}^{i+1} \left( \wt{a}_k L(\vc{Q}^{(k)}) \right)
\]
with $i=0,\ldots,s$ where $s$ are the number of stages, $a$, and $\wt{a}$ are the coefficients of the double Butcher tableau defined in \cite{kennedy:2003,giraldo:2013}.  Additionally, 
$\vc{Q}^{(0)}=\qvector^n$ and the solution at time $n+1$ is obtained as follows
\[
\vc{q}^{n+1}=\qvector^n + \Delta t \sum_{k=0}^{s} \left( b_k S(\vc{Q}^{(k)}) \right)
\]
where the coefficients $b$ are also found in \cite{kennedy:2003,giraldo:2013}.
So far we have defined a diagonally-implicit Runge-Kutta (DIRK) method \cite{alexander:1977,butcher:1981a,ascher:1997,boscarino:2009}.  To make the DIRK more efficient, we impose the restriction that all the diagonal values $\wt{a}_{ii}$ to be constant. This allows one construction of the matrix problem which does not change across stage values.  This we now refer to as singly-diagonally-implicit Runge-Kutta (SDIRK).


\section{Sub-grid Scale Models}
\label{sec:sgs_models}

In order to discuss the sub-grid scale models required for the nonhydrostatic atmospheric models, let us write the equations in the following compact form  
\[
\diff{\vc{q}}{t} = S_D(\vc{q}) + S_P(\vc{q})
\]
where $\vc{q}$ is the solution vector, $S_D$ denotes the RHS due to the dry dynamics while $S_P$ denotes the RHS due to the moist physics. We have already described $S_D$ so let us now focus on $S_P$.

\subsection{Moist Physics}
In MLAM, we propose to use a simplified moisture process (e.g., warm rain Kessler physics) with a Lilly-Smagorinsky type mixing scheme.    (Do we need long-wave radiation? Other such schemes?  If so, which ones?)

\subsection{Topography}
Will be incorporated at a later date.

\input{computing_aspects}


\section{Computing Aspects}
\label{sec:computing_aspects}

Let us decompose the computing aspects into the following groups
\begin{enumerate}
\item workflow language
\item parallelization API
\item many-core API
\item graph-partitioning and grid generation

\end{enumerate}

\subsection{Workflow Language}
Although Python is a popular workflow language, we will likely explore Julia as another option.  The reasons for possibly using Julia are: 
\begin{itemize}
\item We would like to use one language for both prototyping and workflow development,
\item Unlike Python, Julia was built for high-performance computing (see Sec.\ \ref{sec:computing_aspects/manycore}),
\item If we engage with the Julia community, we can get many good students to participate in various forms,
\item Risk-mitigation plan includes falling back to pure C code with Python scaffolding and OCCA kernels.
\end{itemize} 

\subsection{Parallelization API}
We propose to use the Message-Passing Interface (MPI) for communicating across processors and nodes (with multiple processors).  One of the NPS team members (Lucas or Jeremy?) has written Julia wrappers for MPI.

\subsection{Many-core API}
\label{sec:computing_aspects/manycore}
We propose to use a GPU library for accessing the GPUs. The NPS team has vast experience in this area. For example, the NPS team ported NUMA using OCCA2 with a CUDA back-end to run on the Titan supercomputer using 16,000 GPU cards achieving very good weak scaling (see \cite{abdi:2016b,abdi:2018}). The approach will be to write all of the compute-kernels in either GPUArrays (from Julia), OCCA2, or CUDA. From our perspective, the compute-kernel is the focus and most GPU-ready kernels look more or less the same (OCCA, CUDA, and OpenCL). 

\subsection{Graph-Partitioning and Grid Generation}
One of the NPS team members (Jeremy Kozdon) has written Julia wrappers to the p4est library developed by another NPS team member (Lucas Wilcox).  We propose to use p4est for both grid-generation and graph-partitioning or Metis with a specific grid generator for both the LES and global domains. The global domain will use a cubed-sphere grid while the LES domains will use a logically Cartesian cube grid.

\subsection{Code-base Repository}
The code is maintained in Github under the name: Climate Modeling Alliance.

\subsection{Software Management}
Software engineers are required in order to maintain the coupled software-base and to have a centralized person "in charge" of the software code.  It could also be helpful to have a support person who can dedicate time to help with HPC issues on running on the specific Caltech cluster that we will use.  

\subsection{Computing Hardware}
We propose to use about \$30K for purchasing a number of GPU cards.  Most of the development work will be performed on this new GPU cluster at NPS.  We will also  time available to us on the Caltech cluster. We also need to consider which types of computers we will be targeting (e.g., Summit at ORNL) although this will not happen until after year 1.


\section{Machine Learning}
\label{sec:machine_learning}

In this section, we shall describe the role of the non-hydrostatic atmospheric models in the machine learning/data assimilation approach.  To make the exposition clear, let us represent the model in the following way
\[
\diff{\vc{q}}{t} = S_C(\vc{q}) + S_{NC}(\vc{q})
\]
where $\vc{q}$ is the solution vector, $S_C$ denotes the computable terms on the RHS of the equations while $S_{NC}$ denotes the non-computable parameters.  Examples of computable terms includes the full dry dynamics in addition to explicit convection.  Non-computable terms are those that are below the sub-grid scales of even an LES model.  These terms will be obtained from observational data.  Let us describe the nature of this data and how often it needs to be read in.

\subsection{Non-computable Terms}
What sort of data will we be reading in and how often? Once per simulation?  

\subsection{LES Model}
The LES model will require approximately 1 million DOF.  We are targeting 10-100 meter resolutions at this range.

\subsection{Global Model}
Need to describe the process of how to spin-off the LES models and use them to improve the global model. 200 km global resolutions or better if we can afford it. 


%-------Bibliography
\bibliographystyle{siam}
\bibliography{Giraldo_refs}

\end{document}
